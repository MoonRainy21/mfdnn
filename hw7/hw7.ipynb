{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "$\n",
    "\\nu_\\beta(x) = \\log [(\\sum _{i=1}^{n} \\exp(\\beta_i x_i)) ^ \\frac{1}{\\beta}] \\\\\n",
    "\\lim_{\\beta \\to \\infty} \\nu_\\beta(x) = \\lim_{\\beta \\to \\infty} \\frac {\\log[(\\sum _{i=1}^{n} \\exp(\\beta x_i))]} {\\beta} \\\\\n",
    "$\n",
    "By L'Hopital's rule, we have \\\n",
    "$\n",
    "\\lim_{\\beta \\to \\infty} \\nu_\\beta(x) = \\lim_{\\beta \\to \\infty} \\frac {\\sum _{i=1}^{n} x_i \\exp(\\beta x_i)} {\\sum _{i=1}^{n} \\exp(\\beta x_i)} \\\\\n",
    "= \\lim_{\\beta \\to \\infty} \\frac {\\sum _{i=1}^{n} x_i \\exp(\\beta x_i - \\max_j x_j)} {\\sum _{i=1}^{n} \\exp(\\beta x_i - \\max_j x_j)} \\\\\n",
    "= \\lim_{\\beta \\to \\infty} \\frac {\\sum _{i=1}^{n} x_i 1_{x_i = \\max_j x_j}} {\\sum _{i=1}^{n} 1_{x_i = \\max_j x_j}} \\\\\n",
    "= \\max x_i\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)\n",
    "$\n",
    "\\frac \\partial {\\partial x_j} \\nu_1(x) = \\frac \\partial {\\partial x_j} \\log(\\sum _{i=1}^{n} \\exp(x_i)) \\\\\n",
    "= \\frac {\\exp(x_j)} {\\sum _{i=1}^{n} \\exp(x_i)} \\\\\n",
    "= \\mu(x)_j\n",
    "$\n",
    "\n",
    "$\n",
    "\\nabla \\nu_1(x) \n",
    "= \\mu(x) \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)\n",
    "$\n",
    "(\\nabla \\nu_\\beta(x))_j = \\frac {\\exp(\\beta x_j)} {\\sum _{i=1}^{n} \\exp(\\beta x_i)} \\\\\n",
    "$\n",
    "\n",
    "$\n",
    "\\lim_{\\beta \\to \\infty} (\\nabla \\nu_\\beta(x))_j = \\lim_{\\beta \\to \\infty} \\frac {\\exp(\\beta x_j)} {\\sum _{i=1}^{n} \\exp(\\beta x_i)} \\\\\n",
    "=\\lim_{\\beta \\to \\infty} \\frac {\\exp(\\beta (x_j - x_{i_{max}}))} {\\sum _{i=1}^{n} \\exp(\\beta (x_i - x_{i_{max}}))} \\\\\n",
    "= \\delta_{j, i_{max}} \\\\\n",
    "= e_{i_{max}} \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_params:  2469696\n",
      "linear_params:  58631144\n",
      "conv_params+linear_params:  61100840\n",
      "total_params:  61100840\n",
      "conv_params: 4.042000077249347%\n",
      "linear_params: 95.95799992275064%: \n",
      "Conv Multiplications:  655566528\n",
      "Conv Additions:  655566528\n",
      "Linear Multiplications:  58621952\n",
      "Linear Additions:  58621952\n",
      "Linear Multiplications Percentage: 8.208190644576066%\n",
      "Linear Additions Percentage: 8.208190644576066%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000) :\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) :\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = AlexNet()\n",
    "\n",
    "conv_params = sum(p.numel() for p in model.features.parameters() if p.requires_grad)\n",
    "print('conv_params: ', conv_params)\n",
    "linear_params = sum(p.numel() for p in model.classifier.parameters() if p.requires_grad)\n",
    "print('linear_params: ', linear_params)\n",
    "print('conv_params+linear_params: ', conv_params + linear_params)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('total_params: ', total_params)\n",
    "print('conv_params: {}%'.format((conv_params/total_params)*100))\n",
    "print('linear_params: {}%: '.format((linear_params/total_params)*100))\n",
    "\n",
    "# Count Multiplications and Additions\n",
    "# Convolutions\n",
    "features = model.features\n",
    "input_size = 227\n",
    "multiplications_conv = 0\n",
    "additions_conv = 0\n",
    "for feature in features:\n",
    "    if isinstance(feature, nn.Conv2d):\n",
    "        output_size = (input_size - feature.kernel_size[0] + feature.padding[0] * 2) // feature.stride[0] + 1\n",
    "        multiplications_conv += feature.in_channels * feature.out_channels * (feature.kernel_size[0] ** 2) * ((output_size) ** 2)\n",
    "        input_size = output_size\n",
    "    if isinstance(feature, nn.MaxPool2d):\n",
    "        output_size = (input_size - feature.kernel_size) // feature.stride + 1\n",
    "        input_size = output_size\n",
    "additions_conv = multiplications_conv # Each multiplication has a corresponding addition\n",
    "print('Conv Multiplications: ', multiplications_conv)\n",
    "print('Conv Additions: ', additions_conv)\n",
    "\n",
    "# Linear Layers\n",
    "classifier = model.classifier\n",
    "multiplications_lin = 0\n",
    "additions_lin = 0\n",
    "for layer in classifier:\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        multiplications_lin += layer.in_features * layer.out_features\n",
    "        additions_lin += layer.out_features * layer.in_features\n",
    "print('Linear Multiplications: ', multiplications_lin)\n",
    "print('Linear Additions: ', additions_lin)\n",
    "print('Linear Multiplications Percentage: {}%'.format((multiplications_lin/(multiplications_conv + multiplications_lin))*100))\n",
    "print('Linear Additions Percentage: {}%'.format((additions_lin/(additions_conv + additions_lin))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor(1.1230e-07)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nFor debugging purposes, you may want to match the output of conv1 first before\\nmoving on working on conv2. To do so, you can replace the forward-evaluation\\nfunctions of the two models with \\ndef forward(self, x) :\\n    x = self.conv1(x)\\n    return x\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Instantiate model with BN and load trained parameters\n",
    "class smallNetTrain(nn.Module) :\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "                            nn.BatchNorm2d(16),\n",
    "                            nn.ReLU()\n",
    "                            )      \n",
    "        self.conv2 = nn.Sequential(\n",
    "                            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "                            nn.BatchNorm2d(16),\n",
    "                            nn.ReLU()\n",
    "                            ) \n",
    "        self.fc1 = nn.Sequential(\n",
    "                            nn.Linear(16*32*32, 32*32),\n",
    "                            nn.BatchNorm1d(32*32),\n",
    "                            nn.ReLU()\n",
    "                            )   \n",
    "        self.fc2 = nn.Sequential(\n",
    "                            nn.Linear(32*32, 10),\n",
    "                            nn.ReLU()\n",
    "                            )   \n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.float().view(-1, 16*32*32)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = smallNetTrain()\n",
    "model.load_state_dict(torch.load(\"./smallNetSaved\",map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# Instantiate model without BN\n",
    "class smallNetTest(nn.Module) :\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "                            nn.ReLU()\n",
    "                            )      \n",
    "        self.conv2 = nn.Sequential(\n",
    "                            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "                            nn.ReLU()\n",
    "                            ) \n",
    "        self.fc1 = nn.Sequential(\n",
    "                            nn.Linear(16*32*32, 32*32),\n",
    "                            nn.ReLU()\n",
    "                            )   \n",
    "        self.fc2 = nn.Sequential(\n",
    "                            nn.Linear(32*32, 10),\n",
    "                            nn.ReLU()\n",
    "                            )   \n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.float().view(-1, 16*32*32)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model_test = smallNetTest()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize weights of model without BN\n",
    "\n",
    "conv1_bn_beta, conv1_bn_gamma = model.conv1[1].bias, model.conv1[1].weight\n",
    "conv1_bn_mean, conv1_bn_var = model.conv1[1].running_mean, model.conv1[1].running_var\n",
    "conv2_bn_beta, conv2_bn_gamma = model.conv2[1].bias, model.conv2[1].weight\n",
    "conv2_bn_mean, conv2_bn_var = model.conv2[1].running_mean, model.conv2[1].running_var\n",
    "fc1_bn_beta, fc1_bn_gamma = model.fc1[1].bias, model.fc1[1].weight\n",
    "fc1_bn_mean, fc1_bn_var = model.fc1[1].running_mean, model.fc1[1].running_var\n",
    "eps = 1e-05\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the following parameters\n",
    "model_test.conv1[0].weight.data = model.conv1[0].weight.data * conv1_bn_gamma.view(-1, 1, 1, 1) / torch.sqrt(conv1_bn_var + eps).view(-1, 1, 1, 1)\n",
    "model_test.conv1[0].bias.data = (model.conv1[0].bias.data - conv1_bn_mean) / torch.sqrt(conv1_bn_var + eps) * conv1_bn_gamma + conv1_bn_beta\n",
    "\n",
    "model_test.conv2[0].weight.data = model.conv2[0].weight.data * conv2_bn_gamma.view(-1, 1, 1, 1) / torch.sqrt(conv2_bn_var + eps).view(-1, 1, 1, 1)\n",
    "model_test.conv2[0].bias.data = (model.conv2[0].bias.data - conv2_bn_mean) / torch.sqrt(conv2_bn_var + eps) * conv2_bn_gamma + conv2_bn_beta\n",
    "\n",
    "model_test.fc1[0].weight.data = model.fc1[0].weight.data * fc1_bn_gamma.view(-1, 1) / torch.sqrt(fc1_bn_var + eps).view(-1, 1)\n",
    "model_test.fc1[0].bias.data = (model.fc1[0].bias.data - fc1_bn_mean) / torch.sqrt(fc1_bn_var + eps) * fc1_bn_gamma + fc1_bn_beta\n",
    "\n",
    "model_test.fc2[0].weight.data = model.fc2[0].weight.data\n",
    "model_test.fc2[0].bias.data = model.fc2[0].bias.data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Verify difference between model and model_test\n",
    "\n",
    "model.eval()  \n",
    "# model_test.eval()  # not necessary since model_test has no BN or dropout \n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./cifar_10data/',\n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor(), download = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "diff = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        diff.append(torch.norm(model(images) - model_test(images))**2) \n",
    "        \n",
    "print(max(diff)) # If less than 1e-08, you got the right answer.\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "For debugging purposes, you may want to match the output of conv1 first before\n",
    "moving on working on conv2. To do so, you can replace the forward-evaluation\n",
    "functions of the two models with \n",
    "def forward(self, x) :\n",
    "    x = self.conv1(x)\n",
    "    return x\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.discordapp.net/attachments/947918193924636695/1234409611411329024/Screenshot_20240429_164302.jpg?ex=6630a109&is=662f4f89&hm=490fe4d7775787b604b52f8a767e644b2176bb236f5ed6f54b7a8ee28b62864a&=&format=webp&width=850&height=1118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Average Pixel Difference: 9.156371896770803e-17\n",
      "Files already downloaded and verified\n",
      "Average Pixel Diff: 1.6456181245547169e-16\n"
     ]
    }
   ],
   "source": [
    "from turtle import down\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 18 * 18, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "\n",
    "    ###########################################################  \n",
    "    ### TODO: Complete initialization of self.classifier    ###\n",
    "    ###        by filling in the ...                        ###\n",
    "    ###########################################################\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d (256, 4096, kernel_size=18, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d (4096, 4096, kernel_size=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d (4096, num_classes, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def copy_weights_from(self, net1):\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(self.features), 2):\n",
    "                self.features[i].weight.copy_(net1.features[i].weight)\n",
    "                self.features[i].bias.copy_(net1.features[i].bias)\n",
    "\n",
    "            for i in range(len(self.classifier)):\n",
    "                ####################################################\n",
    "                ### TO DO: Correctly transfer weight of Net1     ###\n",
    "                ####################################################\n",
    "                if i % 2 == 1: continue\n",
    "                self.classifier[i].weight.copy_(net1.classifier[i].weight.view(self.classifier[i].weight.size()))\n",
    "                self.classifier[i].bias.copy_(net1.classifier[i].bias.view(self.classifier[i].bias.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model1 = Net1() # model1 randomly initialized\n",
    "model2 = Net2()\n",
    "model2.copy_weights_from(model1)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "imgs, _ = next(iter(test_loader))\n",
    "diff = torch.mean((model1(imgs) - model2(imgs).squeeze()) ** 2)\n",
    "print(f\"Average Pixel Difference: {diff.item()}\") # should be small\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((36, 38)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "        ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "images, _ = next(iter(test_loader))\n",
    "b, w, h = images.shape[0], images.shape[-1], images.shape[-2]\n",
    "out1 = torch.empty((b, 10, h - 31, w - 31))\n",
    "for i in range(h - 31):\n",
    "    for j in range(w - 31):\n",
    "        ########################################################\n",
    "        ### TO DO: fill in ... to make out1 and out2 equal   ###\n",
    "        ########################################################\n",
    "        out1[:, :, i, j] = model1(images[:, :, i:i + 32, j:j + 32])\n",
    "out2 = model2(images)\n",
    "diff = torch.mean((out1 - out2) ** 2)\n",
    "\n",
    "print(f\"Average Pixel Diff: {diff.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
